"""
RedMesh v1 main API endpoints plugin - for managed execution of decentralized distributed pentesting jobs 
at scale in the Ratio1.ai network

- heterogenous worker orchestration
- dynamic job scheduling
- plugin-based scanning and testing services
- real-time job monitoring and logging via API


```pipeline-example.json
{
  "NAME": "redmesh_api",
  "TYPE": "Void",
  "PLUGINS": [
    {
      "SIGNATURE": "PENTESTER_API_01",
      "INSTANCES": [
        {
          "INSTANCE_ID": "PENTESTER_API_01_DEFAULT",
          "CHECK_JOBS_EACH": 5,
          "NR_LOCAL_WORKERS": 4,
          "WARMUP_DELAY": 30
        }
      ]
    }
  ]
}
```

"""

import ipaddress
import random

from urllib.parse import urlparse

from naeural_core.business.default.web_app.fast_api_web_app import FastApiWebAppPlugin as BasePlugin
from .redmesh_utils import PentestLocalWorker  # Import PentestJob from separate module
from .redmesh_llm_agent_mixin import _RedMeshLlmAgentMixin
from .constants import (
  FEATURE_CATALOG,
  LLM_ANALYSIS_SECURITY_ASSESSMENT,
  LLM_ANALYSIS_VULNERABILITY_SUMMARY,
  LLM_ANALYSIS_REMEDIATION_PLAN,
)

__VER__ = '0.9.0' 

_CONFIG = {
  **BasePlugin.CONFIG,

  "TUNNEL_ENGINE_ENABLED": False,

  'PORT': None,

  "CHAINSTORE_PEERS": [],

  "CHECK_JOBS_EACH" : 5,

  "REDMESH_VERBOSE" : 10,  # Verbosity level for debug messages (0 = off, 1+ = debug)

  "NR_LOCAL_WORKERS" : 8,

  "WARMUP_DELAY" : 30,

  # Defines how ports are split across local workers.
  "DISTRIBUTION_STRATEGY": "SLICE", # "SLICE" or "MIRROR"
  "PORT_ORDER": "SHUFFLE",  # "SHUFFLE" or "SEQUENTIAL"
  "EXCLUDED_FEATURES": [],

  # Run mode: SINGLEPASS (default) or CONTINUOUS_MONITORING
  "RUN_MODE": "SINGLEPASS",
  "MONITOR_INTERVAL": 60,  # seconds between passes in continuous mode
  "MONITOR_JITTER": 5,     # random jitter to avoid simultaneous CStore writes

  # Dune sand walking - random delays between operations to evade IDS detection
  "SCAN_MIN_RND_DELAY": 0.0,  # minimum delay in seconds (0 = disabled)
  "SCAN_MAX_RND_DELAY": 0.0,  # maximum delay in seconds (0 = disabled)

  # LLM Agent API integration for auto-analysis
  "LLM_AGENT_API_ENABLED": False,  # Enable LLM-powered analysis
  "LLM_AGENT_API_HOST": "127.0.0.1",  # Host where LLM Agent API is running
  "LLM_AGENT_API_PORT": None,  # Port for LLM Agent API (required if enabled)
  "LLM_AGENT_API_TIMEOUT": 120,  # Timeout in seconds for LLM API calls
  "LLM_AUTO_ANALYSIS_TYPE": "security_assessment",  # Default analysis type

  # RedMesh attestation submission
  "ATTESTATION_ENABLED": True,

  'VALIDATION_RULES': {
    **BasePlugin.CONFIG['VALIDATION_RULES'],
  },
}

class PentesterApi01Plugin(BasePlugin, _RedMeshLlmAgentMixin):
  """
  RedMesh API plugin for orchestrating decentralized pentest jobs.

  The plugin listens for announced jobs in CStore, spawns local workers to
  cover assigned port ranges, aggregates their reports, and updates the
  distributed job state. It exposes FastAPI endpoints for launching tests,
  inspecting progress, and stopping runs.

  Attributes
  ----------
  CONFIG : dict
    Plugin configuration merged with `BasePlugin` defaults.
  scan_jobs : dict
    Active local jobs keyed by job_id.
  completed_jobs_reports : dict
    Aggregated reports for finished jobs keyed by job_id.
  lst_completed_jobs : list
    List of job_ids that completed locally (used for status responses).
  """
  CONFIG = _CONFIG
  REDMESH_ATTESTATION_DOMAIN = "0xced141225d43c56d8b224d12f0b9524a15dc86df0113c42ffa4bc859309e0d40"


  def on_init(self):
    """
    Initialize plugin state and log available features.

    Returns
    -------
    None
    """
    super(PentesterApi01Plugin, self).on_init()
    self.__features = self._get_all_features()
    # Track active and completed jobs by target
    self.scan_jobs = {}       # target -> PentestJob instance
    self.completed_jobs_reports = {}  # target -> final report dict
    self.lst_completed_jobs = []  # List of completed jobs
    self.__last_checked_jobs = 0
    self.__warmupstart = self.time()
    self.__warmup_done = False
    current_epoch = self.netmon.epoch_manager.get_current_epoch()
    self.P("Started {} plugin in epoch {}. Current features:\n{}".format(
      self.__class__.__name__, current_epoch,
      self.json_dumps(self.__features, indent=2),
    ))
    return


  def _setup_semaphore_env(self):
    """Set semaphore environment variables for paired plugins."""
    localhost_ip = self.log.get_localhost_ip()
    port = self.cfg_port
    self.semaphore_set_env('API_HOST', localhost_ip)
    if port:
      self.semaphore_set_env('API_PORT', str(port))
      self.semaphore_set_env('API_URL', 'http://{}:{}'.format(localhost_ip, port))
    return


  def on_close(self):
    super(PentesterApi01Plugin, self).on_close()
    return


  def P(self, s, *args, **kwargs):
    """
    Prefixed logger for RedMesh messages.

    Parameters
    ----------
    s : str
      Message to log.
    *args
      Positional args forwarded to parent logger.
    **kwargs
      Keyword args forwarded to parent logger.

    Returns
    -------
    Any
      Result of parent logger.
    """
    s = "[REDMESH] " + s
    return super(PentesterApi01Plugin, self).P(s, *args, **kwargs)


  def Pd(self, s, *args, score=-1, **kwargs):
    """
    Print debug message if verbosity level allows.

    Parameters
    ----------
    s : str
      Message to print.
    score : int, optional
      Verbosity threshold (default: -1). Message prints if cfg_redmesh_verbose > score.
    *args
      Additional positional arguments passed to P().
    **kwargs
      Additional keyword arguments passed to P().

    Returns
    -------
    None
    """
    if self.cfg_redmesh_verbose > score:
      s = "[DEBUG] " + s
      self.P(s, *args, **kwargs)
    return


  def _attestation_get_tenant_private_key(self):
    env_name = "R1EN_ATTESTATION_PRIVATE_KEY"
    private_key = self.os_environ.get(env_name, None)
    if private_key:
      private_key = private_key.strip()
    if not private_key:
      return None
    return private_key

  @staticmethod
  def _attestation_pack_cid_obfuscated(report_cid) -> str:
    if not isinstance(report_cid, str) or len(report_cid.strip()) == 0:
      return "0x" + ("00" * 10)
    cid = report_cid.strip()
    if len(cid) >= 10:
      masked = cid[:5] + cid[-5:]
    else:
      masked = cid.ljust(10, "_")
    safe = "".join(ch if 32 <= ord(ch) <= 126 else "_" for ch in masked)[:10]
    data = safe.encode("ascii", errors="ignore")
    if len(data) < 10:
      data = data + (b"_" * (10 - len(data)))
    return "0x" + data[:10].hex()

  @staticmethod
  def _attestation_extract_host(target):
    if not isinstance(target, str):
      return None
    target = target.strip()
    if not target:
      return None
    if "://" in target:
      parsed = urlparse(target)
      if parsed.hostname:
        return parsed.hostname
    host = target.split("/", 1)[0]
    if host.count(":") == 1 and "." in host:
      host = host.split(":", 1)[0]
    return host

  def _attestation_pack_ip_obfuscated(self, target) -> str:
    host = self._attestation_extract_host(target)
    if not host:
      return "0x0000"
    if ".." in host:
      parts = host.split("..")
      if len(parts) == 2 and all(part.isdigit() for part in parts):
        first_octet = int(parts[0])
        last_octet = int(parts[1])
        if 0 <= first_octet <= 255 and 0 <= last_octet <= 255:
          return f"0x{first_octet:02x}{last_octet:02x}"
    try:
      ip_obj = ipaddress.ip_address(host)
    except Exception:
      return "0x0000"
    if ip_obj.version != 4:
      return "0x0000"
    octets = host.split(".")
    first_octet = int(octets[0])
    last_octet = int(octets[-1])
    return f"0x{first_octet:02x}{last_octet:02x}"


  def _submit_attestation(self, job_id: str, job_specs: dict, worker_entry: dict):
    if not self.cfg_attestation_enabled:
      return None
    tenant_private_key = self._attestation_get_tenant_private_key()
    if tenant_private_key is None:
      self.P(
        "RedMesh attestation is enabled but tenant private key is missing. "
        "Expected env var 'R1EN_ATTESTATION_PRIVATE_KEY'.",
        color='y'
      )
      return None

    run_mode = str(job_specs.get("run_mode", "SINGLEPASS")).upper()
    test_mode = 1 if run_mode == "CONTINUOUS_MONITORING" else 0
    workers = job_specs.get("workers", {})
    node_count = len(workers) if isinstance(workers, dict) else 0
    # TODO: replace placeholder score with proper RedMesh vulnerability scoring logic.
    vulnerability_score = 100
    target = job_specs.get("target")
    report_cid = worker_entry.get("report_cid")
    node_eth_address = self.bc.eth_address
    ip_obfuscated = self._attestation_pack_ip_obfuscated(target)
    cid_obfuscated = self._attestation_pack_cid_obfuscated(report_cid)

    tx_hash = self.bc.submit_attestation(
      function_name="submitRedmeshAttestation",
      function_args=[
        test_mode,
        node_count,
        vulnerability_score,
        ip_obfuscated,
        cid_obfuscated,
      ],
      signature_types=["bytes32", "uint8", "uint16", "uint8", "bytes2", "bytes10"],
      signature_values=[
        self.REDMESH_ATTESTATION_DOMAIN,
        test_mode,
        node_count,
        vulnerability_score,
        ip_obfuscated,
        cid_obfuscated,
      ],
      tx_private_key=tenant_private_key,
    )

    result = {
      "job_id": job_id,
      "tx_hash": tx_hash,
      "test_mode": "C" if test_mode == 1 else "S",
      "node_count": node_count,
      "vulnerability_score": vulnerability_score,
      "report_cid": report_cid,
      "node_eth_address": node_eth_address,
    }
    self.P(
      "Submitted RedMesh attestation for "
      f"{job_id} (tx: {tx_hash}, node: {node_eth_address}, score: {vulnerability_score})",
      color='g'
    )
    return result


  def __post_init(self):
    """
    Perform warmup: reconcile existing jobs in CStore, migrate legacy keys,
    and aggregate any incomplete reports.

    Returns
    -------
    None
    """
    all_network_jobs = self.chainstore_hgetall(hkey=self.cfg_instance_id)
    info = ""
    for job_key, job_spec in all_network_jobs.items():
      try:
        normalized_key, normalized_spec = self._normalize_job_record(job_key, job_spec, migrate=True)
        if normalized_key is None:
          info += f"- [INVALID]: from <{job_key}>:\n{job_spec}\n"
          continue
        our_worker = normalized_spec.get("workers", {}).get(self.ee_addr, {})
        raw_report = our_worker.get("result", {}) if isinstance(our_worker, dict) else {}
        needs_aggregation = False
        if isinstance(raw_report, dict):
          sample_value = next(iter(raw_report.values()), None)
          needs_aggregation = isinstance(sample_value, dict) and "local_worker_id" in sample_value
        if needs_aggregation:
          # Merge stranded partial worker outputs left from prior deployments.
          self.P(f"Found incomplete report for {normalized_key}, aggregating...", color='r')
          agg_report = self._get_aggregated_report(raw_report)
          our_worker["result"] = agg_report
          normalized_spec["workers"][self.ee_addr] = our_worker
          self.chainstore_hset(hkey=self.cfg_instance_id, key=normalized_key, value=normalized_spec)
        is_completed = all(
          worker.get("finished") for worker in normalized_spec.get("workers", {}).values()
        ) if normalized_spec.get("workers") else False
        info += (
          f"- [VALID][{'COMPLETED' if is_completed else 'INCOMPLETE'}]"
          f" job <{normalized_key}> from <{normalized_spec.get('launcher')}>:\n"
          f"{self.json_dumps(normalized_spec, indent=2)}\n"
        )
      except Exception as e:
        self.P("Error processing job spec for {}: {}\n{}\n{}".format(
            job_key, job_spec, e, self.trace_info(),
            self.json_dumps(job_spec, indent=2)
          ), color='r'
        )
      #end try
    #end for each job spec
    self.P("RedMesh instance <{}> warmup complete. Monitoring jobs...".format(
        self.cfg_instance_id
      ), 
      boxed=True
    )
    self.P("Current jobs in decentralized instances:\n{}".format(
      info
    ))
    self.__warmup_done = True
    return



  def _get_all_features(self, categs=False):
    """
    Discover all service and web test methods available to workers.

    Parameters
    ----------
    categs : bool, optional
      If True, return a dict keyed by category; otherwise a flat list.

    Returns
    -------
    dict | list
      Mapping or list of method names prefixed with `_service_info_` / `_web_test_`.
    """
    features = {} if categs else []
    PREFIXES = ["_service_info_", "_web_test_"]
    for prefix in PREFIXES:
      methods = [method for method in dir(PentestLocalWorker) if method.startswith(prefix)]
      if categs:
        features[prefix[1:-1]] = methods
      else:
        features.extend(methods)
    return features


  def _normalize_job_record(self, job_key, job_spec, migrate=False):
    """
    Normalize a job record and optionally migrate legacy entries.

    Stage 1 of the multi-job coordination refactor lives here. The helper keeps
    legacy single-key entries compatible while allowing each job to live under
    its own hash key.

    Parameters
    ----------
    job_key : str
      Raw key stored in CStore.
    job_spec : Any
      Raw job specification (expected dict).
    migrate : bool, optional
      If True, rewrite legacy keys to normalized form.

    Returns
    -------
    tuple[str | None, dict | None]
      Normalized key and spec; `(None, None)` when invalid.
    """
    if not isinstance(job_spec, dict):
      return None, None
    normalized = dict(job_spec)
    job_id = normalized.get("job_id") or job_key
    normalized["job_id"] = job_id
    launcher = normalized.get("launcher") or normalized.get("initiator") or job_key
    normalized["launcher"] = launcher
    workers = normalized.get("workers")
    if not isinstance(workers, dict):
      workers = {}
    normalized["workers"] = workers
    if migrate and job_key != job_id:
      self.chainstore_hset(hkey=self.cfg_instance_id, key=job_id, value=normalized)
      self.chainstore_hset(hkey=self.cfg_instance_id, key=job_key, value=None)
      job_key = job_id
    return job_key, normalized


  def _get_worker_entry(self, job_id, job_spec):
    """
    Get the worker entry for this node from the job spec.

    Parameters
    ----------
    job_id : str
      Identifier of the job.
    job_spec : dict
      Job specification stored in CStore.

    Returns
    -------
    dict | None
      Worker entry for this edge node, or None if not assigned.
    """
    workers = job_spec.setdefault("workers", {})
    worker_entry = workers.get(self.ee_addr)
    if worker_entry is None:
      self.Pd("No worker entry found for this node in job spec job_id={}, workers={}".format(
        job_id,
        self.json_dumps(workers)),
      )
    return worker_entry
  
  
  def _launch_job(
    self,
    job_id,
    target,
    start_port,
    end_port,
    network_worker_address,
    nr_local_workers=4,
    exceptions=None,
    port_order=None,
    excluded_features=None,
    enabled_features=None,
    scan_min_delay=0.0,
    scan_max_delay=0.0,
  ):
    """
    Launch local worker threads for a job by splitting the port range.

    Parameters
    ----------
    job_id : str
      Identifier of the job being launched.
    target : str
      Hostname or IP to scan.
    start_port : int
      Inclusive start of port range.
    end_port : int
      Inclusive end of port range.
    network_worker_address : str
      Address of the worker that announced the job.
    nr_local_workers : int, optional
      Number of worker threads to spawn.
    exceptions : list[int], optional
      Ports to exclude from scanning.
    port_order : str, optional
      Port scanning order: "SHUFFLE" or "SEQUENTIAL".
    excluded_features : list[str], optional
      List of feature names to exclude from scanning.
    enabled_features : list[str], optional
      List of feature names to enable for scanning.
    scan_min_delay: float, optional
      Minimum random delay between scan operations.
    scan_max_delay: float, optional
      Maximum random delay between scan operations.

    Returns
    -------
    dict
      Mapping of local_worker_id to `PentestLocalWorker` instances.

    Raises
    ------
    ValueError
      When no ports are available or batches cannot be allocated.
    """
    if excluded_features is None:
      excluded_features = []
    if enabled_features is None:
      enabled_features = []
    local_jobs = {}
    ports = list(range(start_port, end_port + 1))
    batches = []
    if port_order == "SEQUENTIAL":
      ports = sorted(ports) # redundant but explicit
    else:
      port_order = "SHUFFLE"
      random.shuffle(ports)
    nr_ports = len(ports)
    if nr_ports == 0:
      raise ValueError("No ports available for local workers.")
    nr_local_workers = max(1, min(nr_local_workers, nr_ports))
    base_chunk, remainder = divmod(nr_ports, nr_local_workers)
    start = 0
    if exceptions is None:
      exceptions = []
    for i in range(nr_local_workers):
      chunk = base_chunk + (1 if i < remainder else 0)
      end = start + chunk
      batch = ports[start:end]
      if batch:
        batches.append(batch)
      start = end
    #endfor create batches
    if not batches:
      raise ValueError("Unable to allocate port batches to workers.")
    if job_id not in self.scan_jobs:
      self.scan_jobs[job_id] = {}
    for i, batch in enumerate(batches):
      try:
        self.P("Launching {} requested by {} for target {} - {} ports. Port order {}".format(
          job_id, network_worker_address,
          target, len(batch), port_order
        ))
        batch_job = PentestLocalWorker(
          owner=self,
          local_id_prefix=str(i + 1),
          target=target,
          job_id=job_id,
          initiator=network_worker_address,
          exceptions=exceptions,
          worker_target_ports=batch,
          excluded_features=excluded_features,
          enabled_features=enabled_features,
          scan_min_delay=scan_min_delay,
          scan_max_delay=scan_max_delay,
        )
        batch_job.start()
        local_jobs[batch_job.local_worker_id] = batch_job
      except Exception as exc:
        self.P(
          "Failed to launch batch local job for ports [{}-{}]. Port order {}: {}".format(
            min(batch) if batch else "-",
            max(batch) if batch else "-",
            port_order,
            exc
          ),
          color='r'
        )
    #end for each batch launch a PentestLocalWorker
    if not local_jobs:
      raise ValueError("No local workers could be launched for the requested port range.")
    return local_jobs

  def _maybe_launch_jobs(self, nr_local_workers=None):
    """
    Launch new PentestJob threads for announced pentest targets.

    Called periodically from `process`.

    Parameters
    ----------
    nr_local_workers : int, optional
      Override for number of local workers; defaults to config.

    Returns
    -------
    None
    """
    if self.time() - self.__last_checked_jobs > self.cfg_check_jobs_each:      
      self.__last_checked_jobs = self.time()            
      all_jobs = self.chainstore_hgetall(hkey=self.cfg_instance_id)
      for job_key, job_specs in all_jobs.items():
        normalized_key, job_specs = self._normalize_job_record(job_key, job_specs, migrate=True)
        if normalized_key is None:
          continue  
        target = job_specs.get("target")
        job_id = job_specs.get("job_id", normalized_key)
        port_order = job_specs.get("port_order", self.cfg_port_order)
        excluded_features = job_specs.get("excluded_features", self.cfg_excluded_features)
        enabled_features = job_specs.get("enabled_features", [])
        if job_id is None:
          continue
        worker_entry = self._get_worker_entry(job_id, job_specs)
        if worker_entry is None:
          # This node is not assigned to this job, skip it
          continue
        current_worker_finished = worker_entry.get("finished", False)
        if current_worker_finished:
          continue

        is_in_progress_target = job_id in self.scan_jobs
        is_closed_target = job_id in self.completed_jobs_reports

        # Check if this is a continuous monitoring job where our worker was reset
        # (launcher reset our finished flag for next pass) - clear local tracking
        # Only applies to CONTINUOUS_MONITORING and only when job is not currently running
        run_mode = job_specs.get("run_mode", "SINGLEPASS")
        if run_mode == "CONTINUOUS_MONITORING" and is_closed_target and not is_in_progress_target:
          # Our worker entry was reset by launcher for next pass - clear local state
          self.P(f"Detected worker reset for job {job_id}, clearing local tracking for next pass")
          self.completed_jobs_reports.pop(job_id, None)
          if job_id in self.lst_completed_jobs:
            self.lst_completed_jobs.remove(job_id)
          is_closed_target = False

        # If job not already running and not completed, start a new thread
        if not is_in_progress_target and not is_closed_target:
          launcher = job_specs.get("launcher")
          launcher_alias = job_specs.get("launcher_alias")
          is_current_node_launcher = self.ee_addr == launcher
          self.P("Starting job {}, target {} from {}".format(
            job_id,
            target,
            f"{launcher_alias} <{launcher}>" if is_current_node_launcher else "myself"),
            boxed=True
          )
          start_port = worker_entry.get("start_port")
          if start_port is None:
            self.P("No start port specified, defaulting to 1.")
            start_port = 1
          end_port = worker_entry.get("end_port")
          if end_port is None:
            self.P("No end port specified, defaulting to 65535.")
            end_port = 65535
          exceptions = job_specs.get("exceptions", [])
          # Ensure exceptions is always a list (handle legacy string format)
          if not isinstance(exceptions, list):
            exceptions = []
          scan_min_delay = job_specs.get("scan_min_delay", self.cfg_scan_min_rnd_delay)
          scan_max_delay = job_specs.get("scan_max_delay", self.cfg_scan_max_rnd_delay)
          workers_requested = nr_local_workers if nr_local_workers is not None else self.cfg_nr_local_workers
          self.P("Using {} local workers for job {}".format(workers_requested, job_id))
          try:
            local_jobs = self._launch_job(
              job_id=job_id,
              target=target,
              start_port=start_port,
              end_port=end_port,
              network_worker_address=launcher,
              nr_local_workers=workers_requested,
              exceptions=exceptions,
              port_order=port_order,
              excluded_features=excluded_features,
              enabled_features=enabled_features,
              scan_min_delay=scan_min_delay,
              scan_max_delay=scan_max_delay,
            )
          except ValueError as exc:
            self.P(f"Skipping job {job_id}: {exc}", color='r')
            worker_entry["finished"] = True
            worker_entry["error"] = str(exc)
            self.chainstore_hset(hkey=self.cfg_instance_id, key=job_id, value=job_specs)
            continue
          self.scan_jobs[job_id] = local_jobs
        #endif need to launch new job
      #end for each potential new job
    #endif it is time to check
    return
  
  
  def _get_aggregated_report(self, local_jobs):
    """
    Aggregate results from multiple local workers.

    Parameters
    ----------
    local_jobs : dict
      Mapping of worker id to result dicts.

    Returns
    -------
    dict
      Aggregated report with merged open ports, service info, etc.
    """
    dct_aggregated_report = {}
    type_or_func, field = None, None
    try:
      if local_jobs:
        self.P(f"Aggregating reports from {len(local_jobs)} local jobs...")
        for local_worker_id, local_job_status in local_jobs.items():
          aggregation_fields = PentestLocalWorker.get_worker_specific_result_fields()
          for field in local_job_status:          
            if field not in dct_aggregated_report:
              dct_aggregated_report[field] = local_job_status[field]
            elif field in aggregation_fields:
              type_or_func = aggregation_fields[field]
              if field not in dct_aggregated_report:
                field_type = type(local_job_status[field])
                dct_aggregated_report[field] = field_type()
              #endif
              if isinstance(dct_aggregated_report[field], list):
                existing = set(dct_aggregated_report[field])
                merged = existing.union(local_job_status[field])
                try:
                  dct_aggregated_report[field] = sorted(merged)
                except TypeError:
                  dct_aggregated_report[field] = list(merged)
              elif isinstance(dct_aggregated_report[field], dict):
                dct_aggregated_report[field] = self.merge_objects_deep(
                  dct_aggregated_report[field],
                  local_job_status[field])
              else:
                _existing = dct_aggregated_report[field]
                _new = local_job_status[field]
                dct_aggregated_report[field] = type_or_func([_existing, _new])
              # end if aggregation type
            # end if standard (one time) or aggregated fields
          # for each field in this local job
        # for each local job
        self.P(f"Report aggregation done.")
      # endif we have local jobs
    except Exception as exc:
      self.P("Error during report aggregation: {}:\n{}\n{}\ntype_or_func={}, field={}".format(
        exc, self.trace_info(),
        self.json_dumps(dct_aggregated_report, indent=2),
        type_or_func, field
      ))
    return dct_aggregated_report

  # todo: move to helper
  def merge_objects_deep(self, obj_a, obj_b):
    """
    Deeply merge two objects (dicts, lists, sets).

    Parameters
    ----------
    obj_a : Any
      First object.
    obj_b : Any
      Second object.

    Returns
    -------
    Any
      Merged object.
    """
    if isinstance(obj_a, dict) and isinstance(obj_b, dict):
      merged = dict(obj_a)
      for key, value_b in obj_b.items():
        if key in merged:
          merged[key] = self.merge_objects_deep(merged[key], value_b)
        else:
          merged[key] = value_b
      return merged
    elif isinstance(obj_a, list) and isinstance(obj_b, list):
      return list(set(obj_a).union(set(obj_b)))
    elif isinstance(obj_a, set) and isinstance(obj_b, set):
      return obj_a.union(obj_b)
    else:
      return obj_b  # Prefer obj_b in case of conflict


  def _close_job(self, job_id, canceled=False):
    """
    Close a local job, aggregate reports, and persist in CStore.

    Reports are saved to R1FS (IPFS) and only the CID is stored in CStore
    to avoid bloating the distributed state.

    Parameters
    ----------
    job_id : str
      Identifier for the job to close.
    canceled : bool, optional
      Whether job was canceled before completion.

    Returns
    -------
    None
    """
    local_workers = self.scan_jobs.pop(job_id, None)
    if local_workers:
      local_reports = {
        local_worker_id: local_worker.get_status()
        for local_worker_id, local_worker in local_workers.items()
      }
      report = self._get_aggregated_report(local_reports)
      if report:
        raw_job_specs = self.chainstore_hget(hkey=self.cfg_instance_id, key=job_id)
        if raw_job_specs is None:
          self.P(f"Job {job_id} no longer present in chainstore; skipping close sync.", color='r')
          return
        _, job_specs = self._normalize_job_record(job_id, raw_job_specs)
        closing = "Forced" if canceled else "Post finish"
        worker_entry = job_specs.setdefault("workers", {}).setdefault(self.ee_addr, {})
        worker_entry["finished"] = True
        worker_entry["canceled"] = canceled

        # Save full report to R1FS and store only CID in CStore
        if report:
          try:
            report_cid = self.r1fs.add_json(report, show_logs=False)
            if report_cid:
              worker_entry["report_cid"] = report_cid
              worker_entry["result"] = None  # No blob in CStore
              self.P(f"Report saved to R1FS with CID: {report_cid}")
            else:
              # Fallback: store report directly if R1FS fails
              self.P("R1FS add_json returned None, storing report directly in CStore", color='y')
              worker_entry["report_cid"] = None
              worker_entry["result"] = report
          except Exception as e:
            # Fallback: store report directly if R1FS fails
            self.P(f"Failed to save report to R1FS: {e}. Storing directly in CStore", color='r')
            worker_entry["report_cid"] = None
            worker_entry["result"] = report
        else:
          self.P(f"No report data to save for job {job_id}", color='y')
          worker_entry["report_cid"] = None
          worker_entry["result"] = report

        # Best-effort on-chain summary; failures must not block job closure.
        try:
          redmesh_attestation = self._submit_attestation(
            job_id=job_id,
            job_specs=job_specs,
            worker_entry=worker_entry
          )
          if redmesh_attestation is not None:
            worker_entry["redmesh_attestation"] = redmesh_attestation
        except Exception as exc:
          self.P(
            f"Failed to submit RedMesh attestation for job {job_id}: {exc}",
            color='r'
          )

        # Re-read job_specs to avoid overwriting concurrent updates (e.g., pass_history)
        fresh_job_specs = self.chainstore_hget(hkey=self.cfg_instance_id, key=job_id)
        if fresh_job_specs and isinstance(fresh_job_specs, dict):
          fresh_job_specs["workers"][self.ee_addr] = worker_entry
          job_specs = fresh_job_specs

        self.P("{} closing job_id {}:\n{}".format(
          closing,
          job_id,
          self.json_dumps(job_specs, indent=2)
        ))
        self.chainstore_hset(hkey=self.cfg_instance_id, key=job_id, value=job_specs)
    return


  def _maybe_close_jobs(self):
    """
    Inspect running jobs and close those whose workers have finished.

    Returns
    -------
    None
    """
    for job_id, local_workers in list(self.scan_jobs.items()):
      all_workers_done = True
      any_canceled_worker = False
      reports = {}
      job : PentestLocalWorker = None
      initiator = None
      nr_local_workers = len(local_workers)
      for local_worker_id, job in local_workers.items():
        # If thread finished or job flagged as done, collect result
        if not job.thread.is_alive() or job.state.get("done"):
          if job_id not in self.completed_jobs_reports:
            self.completed_jobs_reports[job_id] = {}
          # Check if this worker was already reported
          already_reported = local_worker_id in self.completed_jobs_reports[job_id]
          # Prepare final report for this job
          local_worker_report = job.get_status()
          any_canceled_worker = any_canceled_worker or local_worker_report.get("canceled", False)
          # Save completed report
          self.completed_jobs_reports[job_id][local_worker_id] = local_worker_report
          reports[local_worker_id] = local_worker_report
          # Only log once when worker first finishes
          if not already_reported:
            self.P("Worker {} has finished job_id {} for target {}:\n{}".format(
              local_worker_id, job_id, local_worker_report['target'],
              self.json_dumps(local_worker_report, indent=2)
            ))
        else:
          all_workers_done = False
        initiator = job.initiator
      #end for each worker
      
      if all_workers_done:
        self.lst_completed_jobs.append(job_id)
        self.P(f"All {nr_local_workers} local workers for job {job_id} from initiator {initiator} have finished.")
        try:
          self._close_job(job_id, canceled=any_canceled_worker)
        except Exception as e:
          self.P(f"Error clearing job from chainstore: {e}")
          # Remove from active jobs
          del self.scan_jobs[job_id]
        #end if
      #end for each local worker of a job
    #end for each job
    return


  def _maybe_finalize_pass(self):
    """
    Launcher finalizes completed passes and orchestrates continuous monitoring.

    For all jobs, this method:
    1. Detects when all workers have finished the current pass
    2. Records pass completion in pass_history

    For CONTINUOUS_MONITORING jobs, additionally:
    3. Schedules the next pass after monitor_interval
    4. Resets all workers when it's time to start the next pass

    Only the launcher node executes this logic.

    Returns
    -------
    None
    """
    all_jobs = self.chainstore_hgetall(hkey=self.cfg_instance_id)

    for job_key, job_specs in all_jobs.items():
      normalized_key, job_specs = self._normalize_job_record(job_key, job_specs)
      if normalized_key is None:
        continue

      # Only launcher manages pass finalization
      is_launcher = job_specs.get("launcher") == self.ee_addr
      if not is_launcher:
        continue

      workers = job_specs.get("workers", {})
      if not workers:
        continue

      run_mode = job_specs.get("run_mode", "SINGLEPASS")
      job_status = job_specs.get("job_status", "RUNNING")
      all_finished = all(w.get("finished") for w in workers.values())
      next_pass_at = job_specs.get("next_pass_at")
      job_pass = job_specs.get("job_pass", 1)
      job_id = job_specs.get("job_id")
      pass_history = job_specs.setdefault("pass_history", [])

      # Skip jobs that are already finalized or stopped
      if job_status in ("FINALIZED", "STOPPED"):
        continue

      if all_finished and next_pass_at is None:
        # ═══════════════════════════════════════════════════
        # STATE: All peers completed current pass
        # ═══════════════════════════════════════════════════

        #PoT

        pass_history.append({
          "pass_nr": job_pass,
          "completed_at": self.time(),
          "reports": {addr: w.get("report_cid") for addr, w in workers.items()}
        })

        # Handle SINGLEPASS - set FINALIZED and exit (no scheduling)
        if run_mode == "SINGLEPASS":
          job_specs["job_status"] = "FINALIZED"
          job_specs["date_updated"] = self.time()
          job_specs["date_finalized"] = self.time()
          self.P(f"[SINGLEPASS] Job {job_id} complete. Status set to FINALIZED.")

          # Run LLM auto-analysis on aggregated report (launcher only)
          if self.cfg_llm_agent_api_enabled:
            self._run_aggregated_llm_analysis(job_id, job_specs, workers, pass_nr=job_pass)

          self.chainstore_hset(hkey=self.cfg_instance_id, key=job_key, value=job_specs)
          continue

        # CONTINUOUS_MONITORING logic below

        # Check if soft stop was scheduled
        if job_status == "SCHEDULED_FOR_STOP":
          job_specs["job_status"] = "STOPPED"
          job_specs["date_updated"] = self.time()
          job_specs["date_finalized"] = self.time()
          self.P(f"[CONTINUOUS] Pass {job_pass} complete for job {job_id}. Status set to STOPPED (soft stop was scheduled)")

          # Run LLM auto-analysis on aggregated report (launcher only)
          if self.cfg_llm_agent_api_enabled:
            self._run_aggregated_llm_analysis(job_id, job_specs, workers, pass_nr=job_pass)

          self.chainstore_hset(hkey=self.cfg_instance_id, key=job_key, value=job_specs)
          continue
        # end if

        # Run LLM auto-analysis for this pass (launcher only)
        if self.cfg_llm_agent_api_enabled:
          self._run_aggregated_llm_analysis(job_id, job_specs, workers, pass_nr=job_pass)

        # Schedule next pass
        interval = job_specs.get("monitor_interval", self.cfg_monitor_interval)
        jitter = random.uniform(0, self.cfg_monitor_jitter)
        job_specs["next_pass_at"] = self.time() + interval + jitter
        job_specs["date_updated"] = self.time()

        self.P(f"[CONTINUOUS] Pass {job_pass} complete for job {job_id}. Next pass in {interval}s (+{jitter:.1f}s jitter)")
        self.chainstore_hset(hkey=self.cfg_instance_id, key=job_key, value=job_specs)

        # Clear from completed_jobs_reports to allow relaunch
        self.completed_jobs_reports.pop(job_id, None)
        if job_id in self.lst_completed_jobs:
          self.lst_completed_jobs.remove(job_id)

      elif run_mode == "CONTINUOUS_MONITORING" and all_finished and next_pass_at and self.time() >= next_pass_at:
        # ═══════════════════════════════════════════════════
        # STATE: Interval elapsed, start next pass
        # ═══════════════════════════════════════════════════
        job_specs["job_pass"] = job_pass + 1
        job_specs["next_pass_at"] = None

        for addr in workers:
          workers[addr]["finished"] = False
          workers[addr]["result"] = None
          workers[addr]["report_cid"] = None
        # end for each worker reset

        self.P(f"[CONTINUOUS] Starting pass {job_pass + 1} for job {job_id}", boxed=True)
        self.chainstore_hset(hkey=self.cfg_instance_id, key=job_key, value=job_specs)

        # Clear local tracking to allow relaunch
        self.completed_jobs_reports.pop(job_id, None)
        if job_id in self.lst_completed_jobs:
          self.lst_completed_jobs.remove(job_id)
    #end for each job
    return


  def _get_all_network_jobs(self):
    """
    Retrieve all jobs tracked in CStore for this instance.

    Returns
    -------
    dict
      Raw mapping from job keys to specs.
    """
    all_workers_and_jobs = self.chainstore_hgetall(hkey=self.cfg_instance_id)
    return all_workers_and_jobs


  def _get_job_from_cstore(self, job_id: str):
    """
    Fetch a normalized job spec from CStore by job_id.

    Parameters
    ----------
    job_id : str
      Identifier to search for.

    Returns
    -------
    dict | None
      Normalized job spec or None if not found.
    """
    all_workers_and_jobs = self._get_all_network_jobs()
    found = None
    for job_key, job_specs in all_workers_and_jobs.items():
      _, normalized = self._normalize_job_record(job_key, job_specs)
      if normalized and normalized.get("job_id") == job_id:
        found = normalized
        break
    return found


  def _get_job_status(self, job_id : str):
    """
    Build a status or report payload for a job.

    Parameters
    ----------
    job_id : str
      Identifier of the job to inspect.

    Returns
    -------
    dict
      Status payload indicating running/completed/network_tracked/not_found.
    """
    target = None
    local_workers = self.scan_jobs.get(job_id)
    jobs_network_state = self._get_job_from_cstore(job_id)
    result = {}
    # first check if in completed jobs
    if job_id in self.lst_completed_jobs: 
      # dont check in the reports that might contain only from some local workers
      local_workers_reports = self.completed_jobs_reports[job_id]
      some_worker = list(local_workers_reports.keys())[0]
      target = local_workers_reports[some_worker]["target"]
      result = {
        "job_id": job_id,
        "target": target,
        "status": "completed",
        "report": self.completed_jobs_reports[job_id]
      }
    
    elif local_workers:
      # If job is currently running, return progress info   
      statuses = {}
      for local_worker_id, job in local_workers.items():
        statuses[local_worker_id] = job.get_status()
      #end for each local worker
      result = statuses
    elif jobs_network_state:
      result = {
        "job_id": job_id,
        "target": jobs_network_state.get("target"),
        "status": "network_tracked",
        "job": jobs_network_state
      }
    # Job not found
    else:
      # TODO: check job in cstore maybe it was finished some time 
      #       ago before current deployment
      result = {
        "job_id": job_id,
        "target": target,
        "status": "not_found",
        "message": "No such job is running or has been completed on this worker."
      }
    #endif
    return result


  """
  
  Endpoints:
  
  """

  @BasePlugin.endpoint
  def list_features(self):
    """
    List available service and web test features.

    Returns
    -------
    dict
      Mapping of categories to lists of feature names.
    """
    result = {"features": self._get_all_features(categs=True)}
    return result


  @BasePlugin.endpoint
  def get_feature_catalog(self):
    """
    Return the feature catalog with grouped features, labels, and descriptions.

    The catalog provides human-readable groupings of features for UI display,
    along with the actual method names for each group.

    Returns
    -------
    dict
      Feature catalog with categories and all available methods.
    """
    all_methods = self._get_all_features()
    return {
      "catalog": FEATURE_CATALOG,
      "all_methods": all_methods,
    }


  @BasePlugin.endpoint(method="post")
  def launch_test(
    self,
    target: str = "",
    start_port: int = 1, end_port: int = 65535,
    exceptions: str = "64297", #todo format -> list
    distribution_strategy: str = "",
    port_order: str = "",
    excluded_features: list[str] = None,
    run_mode: str = "",
    monitor_interval: int = 0,
    scan_min_delay: float = 0.0,
    scan_max_delay: float = 0.0,
    task_name: str = "",
    task_description: str = "",
    selected_peers: list[str] = None,
  ):
    """
    Start a pentest on the specified target.

    Announces the job to the network via CStore; actual execution is handled
    asynchronously by worker threads.

    Parameters
    ----------
    target : str, optional
      Hostname or IP to scan.
    start_port : int, optional
      Inclusive start port, default 1.
    end_port : int, optional
      Inclusive end port, default 65535.
    exceptions : str, optional
      Comma/space separated list of ports to skip.
    distribution_strategy: str, optional
      "MIRROR" to have all workers scan full range; "SLICE" to split range.
    port_order: str, optional
      Defines port scanning order at worker-thread level:
      "SHUFFLE" to randomize port order; "SEQUENTIAL" for ordered scan.
    excluded_features: list[str], optional
      List of feature names to exclude from scanning.
    run_mode: str, optional
      "SINGLEPASS" (default) for one-time scan; "CONTINUOUS_MONITORING" for
      repeated scans at monitor_interval.
    monitor_interval: int, optional
      Seconds between passes in CONTINUOUS_MONITORING mode (0 = use config).
    scan_min_delay: float, optional
      Minimum random delay between scan operations (Dune sand walking).
    scan_max_delay: float, optional
      Maximum random delay between scan operations (Dune sand walking).
    task_name: str, optional
      Human-readable name for the task.
    task_description: str, optional
      Human-readable description for the task.
    selected_peers: list[str], optional
      List of peer addresses to run the test on. If not provided or empty,
      all configured chainstore_peers will be used. Each address must exist
      in the chainstore_peers configuration.

    Returns
    -------
    dict
      Job specification, current worker id, and other active jobs.

    Raises
    ------
    ValueError
      If no target is provided or if selected_peers contains invalid addresses.
    """
    # INFO: This method only announces the job to the network. It does not 
    #       execute the job itself - that part is handled by PentestJob
    #       executed after periodical check from plugin process.
    if excluded_features is None:
      excluded_features = self.cfg_excluded_features or []
    if not target:
      raise ValueError("No target specified.")

    start_port = int(start_port)
    end_port = int(end_port)

    if start_port > end_port:
      raise ValueError("start_port must be less than end_port.")

    if len(exceptions) > 0:
      exceptions = [
        int(x) for x in self.re.findall(r'\d+', exceptions)
        if x.isdigit()
      ]
    else:
      exceptions = []

    # Validate excluded_features against known features and calculate enabled_features for audit
    all_features = self.__features
    if excluded_features:
      invalid = [f for f in excluded_features if f not in all_features]
      if invalid:
        self.P(f"Warning: Unknown features in excluded_features (ignored): {self.json_dumps(invalid)}")
      excluded_features = [f for f in excluded_features if f in all_features]
    enabled_features = [f for f in all_features if f not in excluded_features]

    self.P(f"Excluded features: {self.json_dumps(excluded_features)}")
    self.P(f"Enabled features: {self.json_dumps(enabled_features)}")

    distribution_strategy = str(distribution_strategy).upper()

    if not distribution_strategy or distribution_strategy not in ["MIRROR", "SLICE"]:
      distribution_strategy = self.cfg_distribution_strategy

    port_order = str(port_order).upper()
    if not port_order or port_order not in ["SHUFFLE", "SEQUENTIAL"]:
      port_order = self.cfg_port_order

    # Validate run_mode and monitor_interval
    run_mode = str(run_mode).upper()
    if not run_mode or run_mode not in ["SINGLEPASS", "CONTINUOUS_MONITORING"]:
      run_mode = self.cfg_run_mode
    if monitor_interval <= 0:
      monitor_interval = self.cfg_monitor_interval

    # Validate scan delays (Dune sand walking)
    if scan_min_delay <= 0:
      scan_min_delay = self.cfg_scan_min_rnd_delay
    if scan_max_delay <= 0:
      scan_max_delay = self.cfg_scan_max_rnd_delay
    # Ensure min <= max
    if scan_min_delay > scan_max_delay:
      scan_min_delay, scan_max_delay = scan_max_delay, scan_min_delay

    # Validate and determine which peers to use
    chainstore_peers = self.cfg_chainstore_peers
    if not chainstore_peers:
      raise ValueError("No workers found in chainstore peers configuration.")

    # Validate selected_peers against chainstore_peers
    if selected_peers and len(selected_peers) > 0:
      invalid_peers = [p for p in selected_peers if p not in chainstore_peers]
      if invalid_peers:
        raise ValueError(
          f"Invalid peer addresses not found in chainstore_peers: {invalid_peers}. "
          f"Available peers: {chainstore_peers}"
        )
      active_peers = selected_peers
    else:
      active_peers = chainstore_peers

    num_workers = len(active_peers)
    if num_workers == 0:
      raise ValueError("No workers available for job execution.")

    workers = {}
    if distribution_strategy == "MIRROR":
      for address in active_peers:
        workers[address] = {
          "start_port": start_port,
          "end_port": end_port,
          "finished": False,
          "result": None
        }
    # else if selected strategy is "SLICE"
    else:

      total_ports = end_port - start_port + 1

      base_ports_count = total_ports // num_workers
      rem_ports_count = total_ports % num_workers

      current_start = start_port
      for i, address in enumerate(active_peers):
        if i < rem_ports_count:
          size = base_ports_count + 1
        else:
          size = base_ports_count
        current_end = current_start + size - 1

        workers[address] = {
          "start_port": current_start,
          "end_port": current_end,
          "finished": False,
          "result": None
        }

        current_start = current_end + 1
      # end for chainstore_peers
    # end if

    job_id = self.uuid(8)
    self.P(f"Launching {job_id=} {target=} with {exceptions=}")
    self.P(f"Announcing pentest to workers (instance_id {self.cfg_instance_id})...")
    job_specs = {
      "job_id" : job_id,
      "target": target,
      "exceptions" : exceptions,
      "start_port" : start_port,
      "end_port" : end_port,
      "launcher": self.ee_addr,
      "launcher_alias": self.ee_id,
      "date_created": self.time(),
      "date_updated": self.time(),
      "date_finalized": None,
      "workers" : workers,
      "distribution_strategy": distribution_strategy,
      "port_order": port_order,
      "excluded_features": excluded_features,
      "enabled_features": enabled_features,
      # Job lifecycle: RUNNING | SCHEDULED_FOR_STOP | STOPPED | FINALIZED
      "job_status": "RUNNING",
      # Continuous monitoring fields
      "run_mode": run_mode,
      "monitor_interval": monitor_interval,
      "job_pass": 1,
      "next_pass_at": None,
      "pass_history": [],
      # Dune sand walking
      "scan_min_delay": scan_min_delay,
      "scan_max_delay": scan_max_delay,
      # Human-readable task info
      # TODO: rename to job_
      "task_name": task_name,
      "task_description": task_description,
      # Peer selection (defaults to all chainstore_peers if not specified)
      "selected_peers": active_peers,
    }
    self.chainstore_hset(
      hkey=self.cfg_instance_id,
      key=job_id,
      value=job_specs
    )
    all_network_jobs = self.chainstore_hgetall(hkey=self.cfg_instance_id)
    report = {}
    for other_key, other_spec in all_network_jobs.items():
      normalized_key, normalized_spec = self._normalize_job_record(other_key, other_spec)
      if normalized_key and normalized_key != job_id:
        report[normalized_key] = normalized_spec
    #end for
    
    self.P(f"Current jobs:\n{self.json_dumps(all_network_jobs, indent=2)}")
    result = {
      "job_specs": job_specs,
      "worker": self.ee_addr,
      "other_jobs": report,
    }
    return result


  @BasePlugin.endpoint
  def get_job_status(self, job_id: str):
    """
    Retrieve status or final report of a pentest job.

    Parameters
    ----------
    job_id : str
      Identifier of the job.

    Returns
    -------
    dict
      Status payload as returned by `_get_job_status`.
    """
    # If job has completed, return its report
    return self._get_job_status(job_id)


  @BasePlugin.endpoint
  def get_job_data(self, job_id: str):
    """
    Retrieve the complete job data from CStore.

    Unlike `get_job_status` which returns local worker progress,
    this endpoint returns the full job specification including:
    - All network workers and their completion status
    - Job lifecycle state (RUNNING/SCHEDULED_FOR_STOP/STOPPED/FINALIZED)
    - Launcher info and timestamps
    - Distribution strategy and configuration
    - Pass history for continuous monitoring jobs

    Parameters
    ----------
    job_id : str
      Identifier of the job.

    Returns
    -------
    dict
      Complete job data or error if not found.
    """
    job_specs = self._get_job_from_cstore(job_id)
    if job_specs:
      return {
        "job_id": job_id,
        "found": True,
        "job": job_specs,
      }
    return {
      "job_id": job_id,
      "found": False,
      "message": "Job not found in network store.",
    }


  @BasePlugin.endpoint
  def list_network_jobs(self):
    """
    List all network jobs stored in CStore.

    Returns
    -------
    dict
      Normalized job specs keyed by job_id.
    """
    raw_network_jobs = self.chainstore_hgetall(hkey=self.cfg_instance_id)
    normalized_jobs = {}
    for job_key, job_spec in raw_network_jobs.items():
      normalized_key, normalized_spec = self._normalize_job_record(job_key, job_spec)
      if normalized_key and normalized_spec:
        normalized_jobs[normalized_key] = normalized_spec
    return normalized_jobs
  
  
  @BasePlugin.endpoint
  def list_local_jobs(self):
    """
    List jobs currently running on this worker.

    Returns
    -------
    dict
      Mapping job_id to status payload.
    """
    jobs = {
      job_id: self._get_job_status(job_id)
      for job_id, local_workers in self.scan_jobs.items()
    }
    return jobs
  
  
  @BasePlugin.endpoint
  def stop_and_delete_job(self, job_id : str):
    """
    Stop and delete a pentest job.

    Parameters
    ----------
    job_id : str
      Identifier of the job to stop.

    Returns
    -------
    dict
      Status message and job_id.
    """
    # Stop the job if it's running
    local_workers = self.scan_jobs.get(job_id)
    if local_workers:
      self.P(f"Stopping and deleting job {job_id}.")
      for local_worker_id, job in local_workers.items():
        self.P(f"Stopping job {job_id} on local worker {local_worker_id}.")
        job.stop()
      self.P(f"Job {job_id} stopped.")
    # Remove from active jobs
    self.scan_jobs.pop(job_id, None)
    raw_job_specs = self.chainstore_hget(hkey=self.cfg_instance_id, key=job_id)
    if isinstance(raw_job_specs, dict):
      _, job_specs = self._normalize_job_record(job_id, raw_job_specs)
      worker_entry = job_specs.setdefault("workers", {}).setdefault(self.ee_addr, {})
      worker_entry["finished"] = True
      worker_entry["canceled"] = True
      self.chainstore_hset(hkey=self.cfg_instance_id, key=job_id, value=job_specs)
    else:
      self.chainstore_hset(hkey=self.cfg_instance_id, key=job_id, value=None)
    self.P(f"Job {job_id} deleted.")
    return {"status": "success", "job_id": job_id}


  @BasePlugin.endpoint
  def get_report(self, cid: str):
    """
    Retrieve a full report from R1FS by CID.

    Parameters
    ----------
    cid : str
      Content identifier of the report stored in R1FS.

    Returns
    -------
    dict
      The full report data or error message.
    """
    if not cid:
      return {"error": "No CID provided"}
    try:
      report = self.r1fs.get_json(cid)
      if report is None:
        return {"error": "Report not found", "cid": cid}
      return {"cid": cid, "report": report}
    except Exception as e:
      self.P(f"Failed to retrieve report from R1FS: {e}", color='r')
      return {"error": str(e), "cid": cid}


  @BasePlugin.endpoint(method="post")
  def stop_monitoring(self, job_id: str, stop_type: str = "SOFT"):
    """
    Stop continuous monitoring for a job.

    Parameters
    ----------
    job_id : str
      Identifier of the job to stop monitoring.
    stop_type : str, optional
      "SOFT" (default): Let current pass complete, then stop.
      Sets job_status="SCHEDULED_FOR_STOP".
      "HARD": Stop immediately. Sets job_status="STOPPED".

    Returns
    -------
    dict
      Status including job_id and passes completed.
    """
    raw_job_specs = self.chainstore_hget(hkey=self.cfg_instance_id, key=job_id)
    if not raw_job_specs:
      return {"error": "Job not found", "job_id": job_id}

    _, job_specs = self._normalize_job_record(job_id, raw_job_specs)
    if job_specs.get("run_mode") != "CONTINUOUS_MONITORING":
      return {"error": "Job is not in CONTINUOUS_MONITORING mode", "job_id": job_id}

    stop_type = str(stop_type).upper()
    passes_completed = job_specs.get("job_pass", 1)

    if stop_type == "HARD":
      job_specs["job_status"] = "STOPPED"
      job_specs["date_updated"] = self.time()
      job_specs["date_finalized"] = self.time()
      self.P(f"[CONTINUOUS] Hard stop for job {job_id} after {passes_completed} passes")
    else:
      # SOFT stop - let current pass complete
      job_specs["job_status"] = "SCHEDULED_FOR_STOP"
      job_specs["date_updated"] = self.time()
      self.P(f"[CONTINUOUS] Soft stop scheduled for job {job_id} (will stop after current pass)")

    self.chainstore_hset(hkey=self.cfg_instance_id, key=job_id, value=job_specs)

    return {
      "job_status": job_specs["job_status"],
      "stop_type": stop_type,
      "job_id": job_id,
      "passes_completed": passes_completed,
      "pass_history": job_specs.get("pass_history", []),
    }


  @BasePlugin.endpoint(method="post")
  def analyze_job(
      self,
      job_id: str,
      analysis_type: str = "",
      focus_areas: list[str] = None
  ):
    """
    Manually trigger LLM analysis for a completed job.

    Aggregates reports from all workers and runs analysis on the combined data.

    Parameters
    ----------
    job_id : str
      Identifier of the job to analyze.
    analysis_type : str, optional
      Type of analysis: "security_assessment", "vulnerability_summary", "remediation_plan".
    focus_areas : list[str], optional
      Areas to focus on: ["web", "network", "databases", "authentication"].

    Returns
    -------
    dict
      LLM analysis result or error message.
    """
    if not self.cfg_llm_agent_api_enabled:
      return {"error": "LLM Agent API is not enabled", "job_id": job_id}

    if not self.cfg_llm_agent_api_port:
      return {"error": "LLM Agent API port not configured", "job_id": job_id}

    # Get job from CStore
    job_specs = self._get_job_from_cstore(job_id)
    if not job_specs:
      return {"error": "Job not found", "job_id": job_id}

    workers = job_specs.get("workers", {})
    if not workers:
      return {"error": "No workers found for this job", "job_id": job_id}

    # Check if all workers have finished
    all_finished = all(w.get("finished") for w in workers.values())
    if not all_finished:
      return {"error": "Job not yet complete, some workers still running", "job_id": job_id}

    # Collect and aggregate reports from all workers
    aggregated_report = self._collect_aggregated_report(workers)

    if not aggregated_report:
      return {"error": "No report data available for this job", "job_id": job_id}

    # Add job metadata to report for context
    target = job_specs.get("target", "unknown")
    aggregated_report["_job_metadata"] = {
      "job_id": job_id,
      "target": target,
      "num_workers": len(workers),
      "worker_addresses": list(workers.keys()),
      "start_port": job_specs.get("start_port"),
      "end_port": job_specs.get("end_port"),
      "enabled_features": job_specs.get("enabled_features", []),
    }

    # Call LLM Agent API
    analysis_type = analysis_type or self.cfg_llm_auto_analysis_type

    analysis_result = self._call_llm_agent_api(
      endpoint="/analyze_scan",
      method="POST",
      payload={
        "scan_results": aggregated_report,
        "analysis_type": analysis_type,
        "focus_areas": focus_areas,
      }
    )

    if "error" in analysis_result:
      return {
        "error": analysis_result.get("error"),
        "status": analysis_result.get("status"),
        "job_id": job_id,
      }

    # Save analysis to R1FS and store in pass_history
    analysis_cid = None
    pass_history = job_specs.get("pass_history", [])
    current_pass = job_specs.get("job_pass", 1)

    try:
      analysis_cid = self.r1fs.add_json(analysis_result, show_logs=False)
      if analysis_cid:
        # Store in pass_history (find the latest completed pass)
        if pass_history:
          # Update the latest pass entry with analysis CID
          pass_history[-1]["llm_analysis_cid"] = analysis_cid
        else:
          # No pass_history yet - create one
          pass_history.append({
            "pass_nr": current_pass,
            "completed_at": self.time(),
            "reports": {addr: w.get("report_cid") for addr, w in workers.items()},
            "llm_analysis_cid": analysis_cid,
          })
          job_specs["pass_history"] = pass_history

        self.chainstore_hset(hkey=self.cfg_instance_id, key=job_id, value=job_specs)
        self.P(f"Manual LLM analysis saved for job {job_id}, CID: {analysis_cid}")
    except Exception as e:
      self.P(f"Failed to save analysis to R1FS: {e}", color='y')

    return {
      "job_id": job_id,
      "target": target,
      "num_workers": len(workers),
      "pass_nr": pass_history[-1].get("pass_nr") if pass_history else current_pass,
      "analysis_type": analysis_type,
      "analysis": analysis_result,
      "analysis_cid": analysis_cid,
    }


  @BasePlugin.endpoint
  def get_analysis(self, job_id: str = "", cid: str = "", pass_nr: int = None):
    """
    Retrieve LLM analysis for a job or by CID.

    The analysis is generated by the launcher node after all workers complete,
    containing the aggregated results from all distributed workers.

    Parameters
    ----------
    job_id : str, optional
      Identifier of the job to get analysis for.
    cid : str, optional
      Direct CID of the analysis to retrieve.
    pass_nr : int, optional
      Pass number for continuous jobs. If not provided, returns the latest pass.

    Returns
    -------
    dict
      LLM analysis data or error message.
    """
    # If CID provided directly, fetch it
    if cid:
      try:
        analysis = self.r1fs.get_json(cid)
        if analysis is None:
          return {"error": "Analysis not found", "cid": cid}
        return {"cid": cid, "analysis": analysis}
      except Exception as e:
        return {"error": str(e), "cid": cid}

    # Otherwise, look up by job_id
    if not job_id:
      return {"error": "Either job_id or cid must be provided"}

    job_specs = self._get_job_from_cstore(job_id)
    if not job_specs:
      return {"error": "Job not found", "job_id": job_id}

    # Look for analysis in pass_history
    pass_history = job_specs.get("pass_history", [])
    job_status = job_specs.get("job_status", "RUNNING")

    if not pass_history:
      if job_status == "RUNNING":
        return {"error": "Job still running, no passes completed yet", "job_id": job_id, "job_status": job_status}
      return {"error": "No pass history available for this job", "job_id": job_id, "job_status": job_status}

    # Find the requested pass (or latest if not specified)
    target_pass = None
    if pass_nr is not None:
      for entry in pass_history:
        if entry.get("pass_nr") == pass_nr:
          target_pass = entry
          break
      if not target_pass:
        return {"error": f"Pass {pass_nr} not found in history", "job_id": job_id, "available_passes": [e.get("pass_nr") for e in pass_history]}
    else:
      # Get the latest pass
      target_pass = pass_history[-1]

    analysis_cid = target_pass.get("llm_analysis_cid")
    if not analysis_cid:
      return {
        "error": "No LLM analysis available for this pass",
        "job_id": job_id,
        "pass_nr": target_pass.get("pass_nr"),
        "job_status": job_status
      }

    try:
      analysis = self.r1fs.get_json(analysis_cid)
      if analysis is None:
        return {"error": "Analysis not found in R1FS", "cid": analysis_cid, "job_id": job_id}
      return {
        "job_id": job_id,
        "pass_nr": target_pass.get("pass_nr"),
        "completed_at": target_pass.get("completed_at"),
        "cid": analysis_cid,
        "target": job_specs.get("target"),
        "num_workers": len(job_specs.get("workers", {})),
        "total_passes": len(pass_history),
        "analysis": analysis,
      }
    except Exception as e:
      return {"error": str(e), "cid": analysis_cid, "job_id": job_id}


  @BasePlugin.endpoint
  def llm_health(self):
    """
    Check health of the LLM Agent API connection.

    Returns
    -------
    dict
      Health status of the LLM Agent API.
    """
    return self._get_llm_health_status()


  def process(self):
    """
    Periodic task handler: launch new jobs and close completed ones.

    Returns
    -------
    None
    """
    super(PentesterApi01Plugin, self).process()

    if (self.time() - self.__warmupstart) < self.cfg_warmup_delay:
      # we do not start jobs before API warmup
      return
    elif not self.__warmup_done:
      self.__post_init()
    #endif
    # Launch any new jobs
    self._maybe_launch_jobs()
    # Check active jobs for completion
    self._maybe_close_jobs()
    # Finalize completed passes and handle continuous monitoring (launcher only)
    self._maybe_finalize_pass()
    return
