
from naeural_core.business.default.web_app.fast_api_web_app import FastApiWebAppPlugin as BasePlugin
from .pentest_job_helper import PentestJobHelper  # Import PentestJob from separate module

__VER__ = '0.5.1'  # updated version

_CONFIG = {
  **BasePlugin.CONFIG,
  
  'PORT': None,
  
  "CHECK_JOBS_EACH" : 5,
  
  "WARMUP_DELAY" : 30,
  
  
  'VALIDATION_RULES': {
    **BasePlugin.CONFIG['VALIDATION_RULES'],  
  },
}

class PentesterApi01Plugin(BasePlugin):
  """
  RedMesh API - a pentesting meta-plugin for receiving pentesting targets and performing operations.
  Supports asynchronous job execution and performs distributed red-team attacks based on 
  decentralized workers orchestrated using CStore.
  """
  CONFIG = _CONFIG


  def on_init(self):
    super(PentesterApi01Plugin, self).on_init()
    self.__features = self._get_all_features()
    # Track active and completed jobs by target
    self.scan_jobs = {}       # target -> PentestJob instance
    self.completed_jobs_reports = {}  # target -> final report dict
    self.lst_completed_jobs = []  # List of completed jobs
    self.__last_checked_jobs = 0
    self.__warmupstart = self.time()
    self.__warmup_done = False
    current_epoch = self.netmon.epoch_manager.get_current_epoch()
    self.P("Started {} plugin in epoch {}. Current features:\n{}".format(
      self.__class__.__name__, current_epoch, self.__features
    ))
    return
  
  def P(self, s, *args, **kwargs):
    s = "[REDMESH] " + s
    return super(PentesterApi01Plugin, self).P(s, *args, **kwargs)
  
  
  def __post_init(self):
    all_network_jobs = self.chainstore_hgetall(hkey=self.cfg_instance_id)
    info = ""
    for target, job in all_network_jobs.items():
      if not isinstance(job, dict):
        info += f"- INVALID: {target}: {job}\n"
      else:
        info += f"- VALID: {target}: {self.json_dumps(job, indent=2)}\n"
    self.P("Warmup complete. Current jobs for {}:\n{}".format(
      self.cfg_instance_id, 
      info
    ))
    self.__warmup_done = True
    return



  def _get_all_features(self, categs=False):
    features = {} if categs else []
    PREFIXES = ["_service_info_", "_web_test_"]
    for prefix in PREFIXES:
      methods = [method for method in dir(PentestJobHelper) if method.startswith(prefix)]
      if categs:
        features[prefix[1:-1]] = methods
      else:
        features.extend(methods)
    return features


  def _maybe_launch_jobs(self, ports=None, exceptions=[64297], nr_batches=4):
    """
    Launch new PentestJob threads for any announced pentest target.
    Called at each process iteration.
    """
    if self.time() - self.__last_checked_jobs > self.cfg_check_jobs_each:      
      self.__last_checked_jobs = self.time()
      all_jobs = self.chainstore_hgetall(hkey=self.cfg_instance_id)
      for address, job_specs in all_jobs.items():
        if not isinstance(job_specs, dict):
          continue
        target = job_specs.get("target")
        job_id = job_specs.get("job_id", target).replace(".", "")
        workers = job_specs.get("workers", {})
        current_worker_finished = workers.get(self.ee_addr, {}).get("finished", False)
        if job_id is None or current_worker_finished:
          continue  
        # If job not already running and not completed, start a new thread
        closed_target = job_id in self.completed_jobs_reports
        in_progress_target = job_id in self.scan_jobs
        if not in_progress_target and not closed_target:
          if ports is None:
            ports = list(range(65536))          
          batches = []
          ports = sorted(ports)
          nr_ports = len(ports)
          for i in range(nr_batches):
            start = i * (nr_ports // nr_batches)
            end = (i + 1) * (nr_ports // nr_batches)
            batch = [x for x in ports[start:end] if x not in exceptions]
            batches.append(batch)
          #endfor create batches
          if job_id not in self.scan_jobs:
            self.scan_jobs[job_id] = {}
          for batch in batches:
            self.P(f"Launching {job_id} requested by {address} for target {target} - {len(batch)} ports [{min(batch)}-{max(batch)}]")
            batch_job = PentestJobHelper(
              owner=self,
              target=target, 
              job_id=job_id,
              initiator=address,
              worker_target_ports=batch,
            )
            self.scan_jobs[job_id][batch_job.local_worker_id] = batch_job
            batch_job.start()
        #endif
      #enfor
    #endif
    return
  
  
  def _close_job(self, job_id, report=None):
    local_jobs = self.scan_jobs.pop(job_id, None)
    if local_jobs:
      job_specs = self.chainstore_hget(hkey=self.cfg_instance_id, key=self.ee_addr)
      closing = "Forced" if report else "Natural"
      self.P("{} closing job:\n{}\nWith report:\n{}".format(
        closing,
        self.json_dumps(job_specs, indent=2),
        self.json_dumps(report, indent=2)
      ))
      job_specs["workers"][self.ee_addr]["finished"] = True
      job_specs["workers"][self.ee_addr]["result"] = "Compressed report here" # TODO: from report {"local_worker" : report}
      job_specs["workers"][self.ee_addr]["forced_closed"] = report is None
      self.chainstore_hset(hkey=self.cfg_instance_id, key=self.ee_addr, value=job_specs)
    return



  def _maybe_close_jobs(self):
    for job_id, local_workers in list(self.scan_jobs.items()):
      all_workers_done = True
      reports = {}
      for local_worker_id, job in local_workers.items():
        # If thread finished or job flagged as done, collect result
        if not job.thread.is_alive() or job.state.get("done"):
          if job_id not in self.completed_jobs_reports:
            self.completed_jobs_reports[job_id] = {}
          target = job.target
          # Prepare final report for this job
          local_worker_report = {
            "job_id" : job_id,
            "target": target,
            "open_ports": job.state.get("open_ports", []),
            "service_info_results": job.state.get("service_info", {}),
            "web_test_results": job.state.get("web_test_results", {}) 
          }
          # Save completed report
          self.completed_jobs_reports[job_id][local_worker_id] = local_worker_report
          reports[local_worker_id] = local_worker_report
          self.P("Pentest job_id {} for target {} from local worker {} has finished:\n{}".format(
            job_id, target,
            local_worker_id,
            self.json_dumps(local_worker_report, indent=2)
          ))
        else:
          all_workers_done = False
      #end for each worker
      
      if all_workers_done:
        self.lst_completed_jobs.append(job_id)
        self.P(f"All workers for job {job_id} have finished.")
        try:
          self._close_job(job_id, report=reports)
        except Exception as e:
          self.P(f"Error clearing job from chainstore: {e}")
          # Remove from active jobs
          del self.scan_jobs[job_id]
        #end if
      #end for each local worker of a job
    #end for each job
    return
  
  
  def _get_job_status(self, job_id):
    target = None
    if job_id in self.lst_completed_jobs: 
      # dont check in the reports that might contain only from some local workers
      local_workers_reports = self.completed_jobs_reports[job_id]
      some_worker = list(local_workers_reports.keys())[0]
      target = local_workers_reports[some_worker]["target"]
      return {
        "job_id": job_id,
        "target": target,
        "status": "completed",
        "report": self.completed_jobs_reports[job_id]
      }
    
    # If job is currently running, return progress info
    local_workers = self.scan_jobs.get(job_id)
    if local_workers:
      statuses = {}
      for local_worker_id, job in local_workers.items():
        target = job.target
        state = job.state
        completed_tests = state.get("completed_tests", [])
        max_features = len(self.__features) + 1 # +1 from port scanning
        progress = f"{(len(completed_tests) / max_features) * 100 if self.__features else 0:.1f}%"
        ports_scanned = state.get("ports_scanned", [])
        open_ports = state.get("open_ports", [])
        statuses[local_worker_id] = {
          "job_id": job_id, 
          "target": target,
          "status": "in_progress",
          "completed_tests" : state.get("completed_tests", []),
          "progress" : progress,
          "ports_scanned": len(ports_scanned),
          "open_ports": len(open_ports),
          "service_info": state.get("service_info", {}),
          "web_tested": state.get("web_tested", False)
        }
      #end for each local worker
      return statuses
    # Job not found
    return {
      "job_id": job_id,
      "target": target,
      "status": "not_found",
      "message": "No such job is running or has been completed on this worker."
    }


  @BasePlugin.endpoint
  def list_features(self):
    result = {"features": self._get_all_features(categs=True)}
    return result


  @BasePlugin.endpoint
  def launch_test(self, target : str):
    """
    Endpoint to start a pentest on the specified target.
    Announce job to network via CStore and return current jobs.            
    """
    # INFO: This method only announces the job to the network. It does not 
    #       execute the job itself - that part is handled by PentestJob
    #       executed after periodical check from plugin process.
    job_id = self.uuid(8)
    self.P(f"Launching pentest {job_id} on target {target}")
    self.P(f"Announcing pentest to workers (instance_id {self.cfg_instance_id})...")
    job_specs = {
      "job_id" : job_id,
      "target": target,
      "workers" : {
        self.ee_addr: {
          "finished": False,
          "result": None
        }
      },
    }
    self.chainstore_hset(
      hkey=self.cfg_instance_id,
      key=self.ee_addr,
      value=job_specs
    )
    all_network_jobs = self.chainstore_hgetall(hkey=self.cfg_instance_id)
    report = {}
    for launcher, job_specs in all_network_jobs.items():
      is_current_job = isinstance(job_specs, dict) and job_specs.get("target") == target and launcher == self.ee_addr
      if not is_current_job:
        report[launcher] = job_specs
    #end for
    
    self.P(f"Current jobs:\n{self.json_dumps(all_network_jobs, indent=2)}")
    result = {
      "job_specs": job_specs,
      "worker": self.ee_addr,
      "other_jobs": report,
    }
    return result


  @BasePlugin.endpoint
  def get_job_status(self, job_id: str):
    """
    Endpoint to retrieve the status or final report of a pentest job for the given target.
    
    TODO: Data must be extracted from CStore
    """
    # If job has completed, return its report
    return self._get_job_status(job_id)


  @BasePlugin.endpoint
  def list_network_jobs(self):
    """
    Endpoint to list all network jobs.
    """
    all_network_jobs = self.chainstore_hgetall(hkey=self.cfg_instance_id)
    return all_network_jobs
  
  
  @BasePlugin.endpoint
  def list_local_jobs(self):
    jobs = {
      job_id: self._get_job_status(job_id)
      for job_id, local_workers in self.scan_jobs.items()
    }
    return jobs
  
  
  @BasePlugin.endpoint
  def stop_and_delete_job(self, job_id : str):
    """
    Endpoint to stop and delete a pentest job.
    """
    # Stop the job if it's running
    local_workers = self.scan_jobs.get(job_id)
    if local_workers:
      self.P(f"Stopping and deleting job {job_id}.")
      for local_worker_id, job in local_workers.items():
        self.P(f"Stopping job {job_id} on local worker {local_worker_id}.")
        job.stop()
      self.P(f"Job {job_id} stopped.")
    # Remove from active jobs
    self.scan_jobs.pop(job_id, None)
    self.P(f"Job {job_id} deleted.")
    return {"status": "success", "job_id": job_id}


  def process(self):
    """
    Periodically invoked to manage job threads.
    Launches new jobs and checks for completed ones.
    """
    super(PentesterApi01Plugin, self).process()
    
    if (self.time() - self.__warmupstart) < self.cfg_warmup_delay:
      # we do not start jobs before API warmup
      return
    elif not self.__warmup_done:
      self.__post_init()
    #endif 
    # Launch any new jobs
    self._maybe_launch_jobs()
    # Check active jobs for completion
    self._maybe_close_jobs()
    return